{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Dataset Preparation\n",
    "\n",
    "Raw data was obtained from the MovieLens 25M Dataset at [website (https://grouplens.org/datasets/movielens/)][website]. Need to clean and transform the data before any networks can be trained. \"ratings.csv\" contains reviews from users for various movies. A given user and a given movie can each be identified by a unique ID. The review from the user for a movie is in the form of a rating out of 5. Furthermore, there is a \"timestamp\" column with a row for each review, where a given row has a value which is the number of seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7XAjHZFGnXuH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from timeit import default_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "FWRQkw9iohet",
    "outputId": "d7e58ced-f9e6-4155-e82f-3569d165209f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21874402</th>\n",
       "      <td>142226</td>\n",
       "      <td>45517</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1534689228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614241</th>\n",
       "      <td>49403</td>\n",
       "      <td>5034</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1165248674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17301156</th>\n",
       "      <td>112093</td>\n",
       "      <td>96728</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1496380634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638843</th>\n",
       "      <td>24027</td>\n",
       "      <td>2004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>899911761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365331</th>\n",
       "      <td>54496</td>\n",
       "      <td>432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>834265074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating   timestamp\n",
       "21874402  142226    45517     3.0  1534689228\n",
       "7614241    49403     5034     3.0  1165248674\n",
       "17301156  112093    96728     4.0  1496380634\n",
       "3638843    24027     2004     4.0   899911761\n",
       "8365331    54496      432     3.0   834265074"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"D:/Movie Recommendation System Project/data/raw data/ratings.csv\")\n",
    "\n",
    "dataset.sample(n = 5, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Reduction\n",
    "\n",
    "We expect that ratings.csv will not have any null rows. Nevertheless, we can check to make sure and also print a summary of our new dataframe, along with the number of unique user and movie IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lfAKicPon6f",
    "outputId": "31228613-b1bd-424b-a1d1-5265af71e0fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000095 entries, 0 to 25000094\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   user_ID    int64  \n",
      " 1   movie_ID   int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 762.9 MB\n",
      "None\n",
      "Null Rows: Empty DataFrame\n",
      "Columns: [user_ID, movie_ID, rating, timestamp]\n",
      "Index: []\n",
      "Number of unique users: 162541\n",
      "Number of unique movies: 59047\n"
     ]
    }
   ],
   "source": [
    "# Rename columns\n",
    "dataset.columns = [\"user_ID\", \"movie_ID\", \"rating\", \"timestamp\"]\n",
    "\n",
    "# Print summary of dataset\n",
    "print(dataset.info())\n",
    "\n",
    "# Check for any null values in rows\n",
    "print(\"Null Rows:\", dataset[pd.isnull(dataset).any(axis=1)])\n",
    "\n",
    "# Print numbers of unique users and movies\n",
    "print(\"Number of unique users: {}\".format(dataset[\"user_ID\"].nunique()))\n",
    "print(\"Number of unique movies: {}\".format(dataset[\"movie_ID\"].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to later transformations we will make which will increase the size of our dataset, we will choose a random subset of the users in order to reduce the size of the dataset and hence reduce the time required to train and evaluate networks. As per the README.txt file in the \"raw data\" folder, each user has at least 20 reviews. We choose to randomly select users as opposed to simply rows because the latter approach will leave us with some users who then only have a number of reviews which is much less than 20. The results will improve for each user in the evaluation stage as the number of training rows for that given user increases. This is thus a property of our dataset which could be varied later on, such as imposing the restriction that each user must have at least 50 training rows. For now, we will simply use a random subset of users.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-7DCEO30o5qU",
    "outputId": "fff7a5ed-213b-4292-faa5-5ef7e6558840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8303384 entries, 254 to 25000094\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   user_ID    int64  \n",
      " 1   movie_ID   int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 316.7 MB\n",
      "Number of unique users: 53638\n",
      "Number of unique movies: 43232\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Choose random subset of unique users to reduce data preparation and training time cost\n",
    "user_ID_subset = np.random.choice(dataset[\"user_ID\"].unique(), \n",
    "                                size = int(len(dataset[\"user_ID\"].unique()) * 0.33), \n",
    "                                replace = False)\n",
    "\n",
    "dataset = dataset.loc[dataset[\"user_ID\"].isin(user_ID_subset)]\n",
    "\n",
    "# Print summary of smaller dataset\n",
    "dataset.info()\n",
    "print(\"Number of unique users: {}\".format(dataset[\"user_ID\"].nunique()))\n",
    "print(\"Number of unique movies: {}\".format(dataset[\"movie_ID\"].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit Feedback Transformation and Leave-One-Out Methodology\n",
    "\n",
    "For this project, I am interested in building models which can successfully predict whether or not a given user will interact (or watch) with a given movie. For this reason, the implicit feedback format will be used, where a value of 1 indicates an interaction and 0 indicates no interaction. The rows in the current dataset only include interactions between users and movies, and we can hence rename the \"rating\" column to \"interaction\" and change every value to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "5adpuwaDo7Ft",
    "outputId": "8a1ff7ca-8bfe-48a0-b7b3-75f952af330b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ID</th>\n",
       "      <th>movie_ID</th>\n",
       "      <th>interaction</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15858612</th>\n",
       "      <td>102781</td>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>888091760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336347</th>\n",
       "      <td>158112</td>\n",
       "      <td>3897</td>\n",
       "      <td>1</td>\n",
       "      <td>1053819490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20485683</th>\n",
       "      <td>133209</td>\n",
       "      <td>3704</td>\n",
       "      <td>1</td>\n",
       "      <td>1297626782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11856950</th>\n",
       "      <td>76852</td>\n",
       "      <td>32296</td>\n",
       "      <td>1</td>\n",
       "      <td>1119886537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807990</th>\n",
       "      <td>5443</td>\n",
       "      <td>2433</td>\n",
       "      <td>1</td>\n",
       "      <td>944924701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_ID  movie_ID  interaction   timestamp\n",
       "15858612   102781       341            1   888091760\n",
       "24336347   158112      3897            1  1053819490\n",
       "20485683   133209      3704            1  1297626782\n",
       "11856950    76852     32296            1  1119886537\n",
       "807990       5443      2433            1   944924701"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Want implicit feedback\n",
    "# Use 1 for 'interaction' and 0 for 'no interaction'\n",
    "dataset.loc[:, \"rating\"] = 1\n",
    "\n",
    "# Rename columns\n",
    "dataset.columns = [\"user_ID\", \"movie_ID\", \"interaction\", \"timestamp\"]\n",
    "\n",
    "dataset.sample(n = 5, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid a look-ahead bias and implement the leave-one-out test set methodology, we need to group rows by user ID and then rank them in time order. The pandas groupby object and the \"timestamp\" column allow us to do this. The single test set row for each user is selected as the row with a time rank of 1, since we have used descending order. Every other row for a given user is saved in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpjnTu08pEDI",
    "outputId": "df46dc2a-14b8-4a2a-9cb0-e40b8d80fed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "          user_ID  movie_ID  interaction\n",
      "5596867     36255     45722            1\n",
      "6899980     44770     34048            1\n",
      "14554676    94226       608            1\n",
      "10814658    70176      6874            1\n",
      "6091949     39500     33660            1\n",
      "Test Set:\n",
      "          user_ID  movie_ID  interaction\n",
      "494681       3399      2987            1\n",
      "14457181    93602    122886            1\n",
      "2622146     17452      1282            1\n",
      "1568280     10502       260            1\n",
      "22269551   144809      2987            1\n"
     ]
    }
   ],
   "source": [
    "# Group by userID and rank timestamps in descending order for each userID\n",
    "dataset[\"time_rank\"] = dataset.groupby(by = \"user_ID\")[\"timestamp\"].rank(method = \"first\", ascending = False)\n",
    "\n",
    "train_set = dataset[dataset[\"time_rank\"] != 1]\n",
    "train_set = train_set[[\"user_ID\", \"movie_ID\", \"interaction\"]]\n",
    "\n",
    "print(\"Training Set:\")\n",
    "print(train_set.sample(n = 5))\n",
    "\n",
    "test_set = dataset[dataset[\"time_rank\"] == 1]\n",
    "test_set = test_set[[\"user_ID\", \"movie_ID\", \"interaction\"]]\n",
    "\n",
    "print(\"Test Set:\")\n",
    "print(test_set.sample(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the networks to be effective in predicting which movies users will and won't interact with, it also needs to be exposed to unseen movie samples, where the interaction is 0. The dataset doesn't include such rows, however we can randomly select movies which a given user has not seen, assume that the user is not interested in these movies and then append these rows to the dataset with an interaction of 0. This assumption turns out to work well in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "01Vn3QlgpGPd"
   },
   "outputs": [],
   "source": [
    "# Define a function which can create rows for users and movies they haven't interacted with\n",
    "# Unseen movies are labelled with an interaction of 0\n",
    "# Ratio determines the final ratio of unseen to seen movies for each user\n",
    "def append_unseen_samples(overall_dataset, subset, ratio):\n",
    "    user_movie_set = set(zip(subset[\"user_ID\"], subset[\"movie_ID\"]))\n",
    "    \n",
    "    all_movie_IDs = overall_dataset[\"movie_ID\"].unique()\n",
    "    \n",
    "    users = []\n",
    "    movies = []\n",
    "    interactions = []\n",
    "    \n",
    "    count = 0\n",
    "    start = default_timer()\n",
    "    for user, movie in user_movie_set:\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        users.append(user)\n",
    "        movies.append(movie)\n",
    "        interactions.append(1)\n",
    "        \n",
    "        for x in range(ratio):\n",
    "            unseen_movie = np.random.choice(all_movie_IDs)\n",
    "            \n",
    "            # Check if user has interacted with the randomly chosen movie\n",
    "            # If interaction has occured, randomly choose new movie until unseen movie is found\n",
    "            while (user, unseen_movie) in user_movie_set:\n",
    "                unseen_movie = np.random.choice(all_movie_IDs)\n",
    "                \n",
    "            users.append(user)\n",
    "            movies.append(unseen_movie)\n",
    "            interactions.append(0)\n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "        # Print percentage of loop completion and current time elapsed to predict total runtime for loop\n",
    "        print(\"Overall Loop Progress: {:.2f}%\".format((count/len(user_movie_set))*100))\n",
    "        stop = default_timer()\n",
    "        print(\"Current Overall Runtime: {:.2f} minutes\".format((stop - start)/60))\n",
    "        \n",
    "    new_subset = pd.DataFrame(list(zip(users, movies, interactions)), columns = [\"user_ID\", \"movie_ID\", \"interaction\"])    \n",
    "            \n",
    "    ordered_subset = new_subset.sort_values(by = \"user_ID\", ascending = True)\n",
    "    return ordered_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btYeqy8lpQTh",
    "outputId": "d03f6c4d-4e34-48ce-9d47-6d23448cc14d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Loop Progress: 100.00%\n",
      "Current Overall Runtime: 202.78 minutes\n"
     ]
    }
   ],
   "source": [
    "train_set = append_unseen_samples(dataset, train_set, ratio = 4)\n",
    "\n",
    "train_set.to_csv(\"D:/Movie Recommendation System Project/data/data preparation/dataset frac=0.33, ratio=4/train_set.csv\")\n",
    "test_set.to_csv(\"D:/Movie Recommendation System Project/data/data preparation/dataset frac=0.33, ratio=4/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2Vz2DQsqaoH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
